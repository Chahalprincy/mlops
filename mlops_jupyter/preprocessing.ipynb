{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0662c4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imbalanced-learn==0.8.1 -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a881532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nlpaug == 1.1.0 transformers==3.0.2 -q\n",
    "# !pip install snorkel==0.9.8 -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ae2c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nlpaug transformers==4.11.3 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18c75407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import log_loss, precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "445d8016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import json\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nlpaug.augmenter.word as naw\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc8ac203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed=42):\n",
    "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be8b8750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/princychahal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "# stopwords are word which are generally filtered out, because they don't cary much information.\n",
    "STOPWORDS = stopwords.words(\"english\")\n",
    "# lemmatization is normalization process which converts every word to its base root mode\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ce7d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, lower=True, stem=False, stopwords=STOPWORDS):\n",
    "    \"\"\"Clean raw text.\"\"\"\n",
    "    # Lower\n",
    "    if lower:\n",
    "        text = text.lower()\n",
    "\n",
    "    # Remove stopwords\n",
    "    if len(stopwords):\n",
    "        pattern = re.compile(r'\\b(' + r\"|\".join(stopwords) + r\")\\b\\s*\")\n",
    "        text = pattern.sub('', text)\n",
    "\n",
    "    # Spacing and filters\n",
    "    text = re.sub(\n",
    "        r\"([!\\\"'#$%&()*\\+,-./:;<=>?@\\\\\\[\\]^_`{|}~])\", r\" \\1 \", text\n",
    "    )  # add spacing between objects to be filtered\n",
    "    text = re.sub(\"[^A-Za-z0-9]+\", \" \", text)  # remove non alphanumeric chars\n",
    "    text = re.sub(\" +\", \" \", text)  # remove multiple spaces\n",
    "    text = text.strip()  # strip white space at the ends\n",
    "\n",
    "    # Remove links\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "\n",
    "    # Stemming\n",
    "    if stem:\n",
    "        text = \" \".join([stemmer.stem(word, to_lowercase=lower) for word in text.split(\" \")])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de65066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepted tags (external constraint)\n",
    "ACCEPTED_TAGS = [\"natural-language-processing\", \"computer-vision\", \"mlops\", \"graph-learning\"]\n",
    "\n",
    "\n",
    "def preprocess(df, lower, stem, min_freq):\n",
    "    \"\"\"Preprocess the data.\"\"\"\n",
    "    df[\"text\"] = df.title + \" \" + df.description  # feature engineering\n",
    "    df.text = df.text.apply(clean_text, lower=lower, stem=stem)  # clean text\n",
    "\n",
    "    # Replace OOS tags with `other`\n",
    "    oos_tags = [item for item in df.tag.unique() if item not in ACCEPTED_TAGS]\n",
    "    df.tag = df.tag.apply(lambda x: \"other\" if x in oos_tags else x)\n",
    "\n",
    "    # Replace tags below min_freq with `other`\n",
    "    tags = Counter(df.tag.values)\n",
    "    tags_above_freq = Counter(tag for tag in tags.elements()\n",
    "                            if (tags[tag] >= min_freq))\n",
    "    df.tag = df.tag.apply(lambda tag: tag if tag in tags_above_freq else None)\n",
    "    df.tag = df.tag.fillna(\"other\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e58ec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_splits(X, y, train_size=0.7):\n",
    "    \"\"\"Generate balanced data splits.\"\"\"\n",
    "    X_train, X_, y_train, y_ = train_test_split(\n",
    "        X, y, train_size=train_size, stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_, y_, train_size=0.5, stratify=y_)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a42f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoder(object):\n",
    "    \"\"\"Encode labels into unique indices\"\"\"\n",
    "    def __init__(self, class_to_index={}):\n",
    "        self.class_to_index = class_to_index or {}  # mutable defaults ;)\n",
    "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
    "        self.classes = list(self.class_to_index.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.class_to_index)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<LabelEncoder(num_classes={len(self)})>\"\n",
    "\n",
    "    def fit(self, y):\n",
    "        classes = np.unique(y)\n",
    "        for i, class_ in enumerate(classes):\n",
    "            self.class_to_index[class_] = i\n",
    "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
    "        self.classes = list(self.class_to_index.keys())\n",
    "        return self\n",
    "\n",
    "    def encode(self, y):\n",
    "        encoded = np.zeros((len(y)), dtype=int)\n",
    "        for i, item in enumerate(y):\n",
    "            encoded[i] = self.class_to_index[item]\n",
    "        return encoded\n",
    "\n",
    "    def decode(self, y):\n",
    "        classes = []\n",
    "        for i, item in enumerate(y):\n",
    "            classes.append(self.index_to_class[item])\n",
    "        return classes\n",
    "#  Do not understand\n",
    "    def save(self, fp):\n",
    "        with open(fp, \"w\") as fp:\n",
    "            contents = {\"class_to_index\": self.class_to_index}\n",
    "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, fp):\n",
    "        with open(fp, \"r\") as fp:\n",
    "            kwargs = json.load(fp=fp)\n",
    "        return cls(**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21d46fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up\n",
    "min_freq = 75\n",
    "set_seeds()\n",
    "df = pd.read_csv(\"labeled_projects.csv\")\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df = preprocess(df, lower=True, stem=False, min_freq=min_freq)\n",
    "label_encoder = LabelEncoder().fit(df.tag)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = \\\n",
    "    get_data_splits(X=df.text.to_numpy(), y=label_encoder.encode(df.tag))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "525000b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_raw = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f35a52c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tf-idf\n",
    "vectorizer = TfidfVectorizer(analyzer=\"char\", ngram_range=(2,7))  # char n-grams\n",
    "# print (X_train[0])\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_val = vectorizer.transform(X_val)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "# print(X_train[0])\n",
    "# print (X_train.shape)  # scipy.sparse.csr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f1c0e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class counts: [249  55 272  92],\n",
      "class weights: {0: 0.004016064257028112, 1: 0.01818181818181818, 2: 0.003676470588235294, 3: 0.010869565217391304}\n"
     ]
    }
   ],
   "source": [
    "# Class weights\n",
    "counts = np.bincount(y_train)\n",
    "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
    "print (f\"class counts: {counts},\\nclass weights: {class_weights}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bea64dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = SGDClassifier(\n",
    "    loss=\"log\", penalty=\"l2\", alpha=1e-4, max_iter=1,\n",
    "    learning_rate=\"constant\", eta0=1e-1, power_t=0.1,\n",
    "    warm_start=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b616236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00 | train_loss: 1.18299, val_loss: 1.20148\n",
      "Epoch: 10 | train_loss: 0.54027, val_loss: 0.67864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | train_loss: 0.37319, val_loss: 0.55959\n",
      "Epoch: 30 | train_loss: 0.29271, val_loss: 0.50606\n",
      "Epoch: 40 | train_loss: 0.24549, val_loss: 0.47539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50 | train_loss: 0.21513, val_loss: 0.45581\n",
      "Epoch: 60 | train_loss: 0.19445, val_loss: 0.44276\n",
      "Epoch: 70 | train_loss: 0.17978, val_loss: 0.43350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80 | train_loss: 0.16901, val_loss: 0.42670\n",
      "Epoch: 90 | train_loss: 0.16055, val_loss: 0.42135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/princychahal/miniconda3/envs/d2/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluation\n",
    "    train_loss = log_loss(y_train, model.predict_proba(X_train))\n",
    "    val_loss = log_loss(y_val, model.predict_proba(X_val))\n",
    "\n",
    "    if not epoch%10:\n",
    "        print(\n",
    "            f\"Epoch: {epoch:02d} | \"\n",
    "            f\"train_loss: {train_loss:.5f}, \"\n",
    "            f\"val_loss: {val_loss:.5f}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa6a2f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8804728087816324, 0.875, 0.8738912212360173, None)\n",
      "{\n",
      "  \"precision\": 0.8804728087816324,\n",
      "  \"recall\": 0.875,\n",
      "  \"f1\": 0.8738912212360173\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "metrics = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
    "print(metrics)\n",
    "performance = {\"precision\": metrics[0], \"recall\": metrics[1], \"f1\": metrics[2]}\n",
    "print (json.dumps(performance, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e26facc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural-language-processing']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference (with tokens similar to training data)\n",
    "text = \"Transfer learning with transformers for text classification.\"\n",
    "y_pred = model.predict(vectorizer.transform([text]))\n",
    "label_encoder.decode(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52a08381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02063355 0.00259423 0.96928256 0.00748966]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'computer-vision': 0.020633551628573863,\n",
       " 'mlops': 0.002594230407916429,\n",
       " 'natural-language-processing': 0.9692825609694882,\n",
       " 'other': 0.007489656994021604}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probabilities\n",
    "y_prob = model.predict_proba(vectorizer.transform([text]))\n",
    "print(y_prob)\n",
    "{tag:y_prob[0][i] for i, tag in enumerate(label_encoder.classes)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42cb0827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6890960095210326"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine first quantile softmax score for the correct class (on validation split)\n",
    "y_pred = model.predict(X_val)\n",
    "y_prob = model.predict_proba(X_val)\n",
    "threshold = np.quantile([y_prob[i][j] for i, j in enumerate(y_pred)], q=0.25)  # Q1\n",
    "threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "484d4c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom predict function\n",
    "def custom_predict(y_prob, threshold, index):\n",
    "    \"\"\"Custom predict function that defaults\n",
    "    to an index if conditions are not met.\"\"\"\n",
    "    y_pred = [np.argmax(p) if max(p) > threshold else index for p in y_prob]\n",
    "    return np.array(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24dae369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tag(texts):\n",
    "    y_prob = model.predict_proba(vectorizer.transform(texts))\n",
    "    other_index = label_encoder.class_to_index[\"other\"]\n",
    "    y_pred = custom_predict(y_prob=y_prob, threshold=threshold, index=other_index)\n",
    "    return label_encoder.decode(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b72cacef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural-language-processing']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference (with tokens not similar to training data)\n",
    "text = \"Interpretability methods for explaining model behavior.\"\n",
    "predict_tag(texts=[text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d1212f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.9116161616161617,\n",
      "  \"recall\": 0.7569444444444444,\n",
      "  \"f1\": 0.7917810016494227\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "y_prob = model.predict_proba(X_test)\n",
    "other_index = label_encoder.class_to_index[\"other\"]\n",
    "y_pred = custom_predict(y_prob=y_prob, threshold=threshold, index=other_index)\n",
    "metrics = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
    "performance = {\"precision\": metrics[0], \"recall\": metrics[1], \"f1\": metrics[2]}\n",
    "print (json.dumps(performance, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25dc9fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"precision\": 0.9116161616161617,\n",
      "    \"recall\": 0.7569444444444444,\n",
      "    \"f1\": 0.7917810016494227,\n",
      "    \"num_samples\": 144.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Overall metrics\n",
    "overall_metrics = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
    "metrics = {\"overall\": {}, \"class\": {}}\n",
    "metrics[\"overall\"][\"precision\"] = overall_metrics[0]\n",
    "metrics[\"overall\"][\"recall\"] = overall_metrics[1]\n",
    "metrics[\"overall\"][\"f1\"] = overall_metrics[2]\n",
    "metrics[\"overall\"][\"num_samples\"] = np.float64(len(y_test))\n",
    "print (json.dumps(metrics[\"overall\"], indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1b2bab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.        , 1.        , 1.        , 0.36363636]),\n",
       " array([0.66666667, 0.58333333, 0.79310345, 1.        ]),\n",
       " array([0.8       , 0.73684211, 0.88461538, 0.53333333]),\n",
       " array([54, 12, 58, 20]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_metrics = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "class_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26f09d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class metrics\n",
    "class_metrics = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "for i, _class in enumerate(label_encoder.classes):\n",
    "    metrics[\"class\"][_class] = {\n",
    "        \"precision\": class_metrics[0][i],\n",
    "        \"recall\": class_metrics[1][i],\n",
    "        \"f1\": class_metrics[2][i],\n",
    "        \"num_samples\": np.float64(class_metrics[3][i]),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b7eb285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP, FP, FN samples\n",
    "tag = \"mlops\"\n",
    "index = label_encoder.class_to_index[tag]\n",
    "tp, fp, fn = [], [], []\n",
    "for i, true in enumerate(y_test):\n",
    "    pred = y_pred[i]\n",
    "    if index==true==pred:\n",
    "        tp.append(i)\n",
    "    elif index!=true and index==pred:\n",
    "        fp.append(i)\n",
    "    elif index==true and index!=pred:\n",
    "        fn.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5905203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 47, 52, 96, 111, 123, 129]\n",
      "[]\n",
      "[0, 38, 130, 136, 141]\n"
     ]
    }
   ],
   "source": [
    "print (tp)\n",
    "print (fp)\n",
    "print (fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "719461ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144,)\n",
      "(144, 4)\n"
     ]
    }
   ],
   "source": [
    "# y\n",
    "y_prob = model.predict_proba(X_test)\n",
    "print (np.shape(y_test))\n",
    "print (np.shape(y_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e4640fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to show raw text\n",
    "test_df = pd.DataFrame({\"text\": X_test_raw, \"tag\": label_encoder.decode(y_test)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bdf32f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag to inspect\n",
    "tag = \"mlops\"\n",
    "index = label_encoder.class_to_index[tag]\n",
    "indices = np.where(y_test==index)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7e73bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   5,  38,  47,  52,  96, 111, 123, 129, 130, 136, 141]),)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y_test==index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af4cb7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence score for the correct class is below a threshold\n",
    "low_confidence = []\n",
    "min_threshold = 0.5\n",
    "for i in indices:\n",
    "    prob = y_prob[i][index]\n",
    "    if prob <= 0.5:\n",
    "        low_confidence.append({\"text\": test_df.text[i],\n",
    "                               \"true\": label_encoder.index_to_class[y_test[i]],\n",
    "                               \"pred\": label_encoder.index_to_class[y_pred[i]],\n",
    "                               \"prob\": prob})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11fd613a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'pytest pytest framework makes easy write small tests yet scales support complex functional testing',\n",
       "  'true': 'mlops',\n",
       "  'pred': 'other',\n",
       "  'prob': 0.48004704907313744},\n",
       " {'text': 'hidden technical debt machine learning systems using software engineering framework technical debt find common incur massive ongoing maintenance costs real world ml systems',\n",
       "  'true': 'mlops',\n",
       "  'pred': 'other',\n",
       "  'prob': 0.3382731457651776},\n",
       " {'text': 'docker help become effective data scientist look docker perspective data scientist',\n",
       "  'true': 'mlops',\n",
       "  'pred': 'other',\n",
       "  'prob': 0.38298721421694343},\n",
       " {'text': 'neptune ai lightweight experiment management tool fits workflow',\n",
       "  'true': 'mlops',\n",
       "  'pred': 'other',\n",
       "  'prob': 0.253380937421862}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "963d39f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install cleanlab==1.0.1 -q\n",
    "import cleanlab\n",
    "from cleanlab.pruning import get_noise_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc415dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine potential labeling errors\n",
    "label_error_indices = get_noise_indices(\n",
    "            s=y_test,\n",
    "            psx=y_prob,\n",
    "            sorted_index_method=\"self_confidence\",\n",
    "            verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61267326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 41, 140])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_error_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f273d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: extracting structured data templatic documents automatically extract data structured documents invoices receipts etc potential streamline many business workflows\n",
      "true: computer-vision\n",
      "pred: other\n",
      "\n",
      "text: module 2 convolutional neural networks cs231n lecture 5 move fully connected neural networks convolutional neural networks\n",
      "true: computer-vision\n",
      "pred: other\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10\n",
    "for index in label_error_indices[:num_samples]:\n",
    "    print (\"text:\", test_df.iloc[index].text)\n",
    "    print (\"true:\", test_df.iloc[index].tag)\n",
    "    print (\"pred:\", label_encoder.decode([y_pred[index]])[0])\n",
    "    print ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c07dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
